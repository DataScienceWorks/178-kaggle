{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "import mltools.nnet\n",
    "np.random.seed(0)\n",
    "\n",
    "# Load the data\n",
    "X = np.genfromtxt(\"data/X_train.txt\", delimiter=None)\n",
    "Y = np.genfromtxt(\"data/Y_train.txt\", delimiter=None)\n",
    "Xtest = np.genfromtxt(\"data/X_test.txt\",delimiter=None)\n",
    "\n",
    "X, Y = ml.shuffleData(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtr,Xte,Ytr,Yte = ml.splitData(X,Y,0.8)\n",
    "\n",
    "ensemble = [None] * 25\n",
    "Ytr_rf = np.zeros((len(Ytr), 25))\n",
    "Yte_rf = np.zeros((len(Yte), 25))\n",
    "\n",
    "for i in range(25):\n",
    "    Xi, Yi = ml.bootstrapData(Xtr, Ytr)\n",
    "    ensemble[i] = ml.dtree.treeClassify(Xi, Yi, maxDepth=20, nFeatures=10)\n",
    "    Ytr_rf[:,i], Yte_rf[:,i] = ensemble[i].predict(Xtr), ensemble[i].predict(Xte)\n",
    "    \n",
    "    errorTrain, errorValid = np.zeros(4), np.zeros(4)\n",
    "    bags = [1, 5, 10, 25]\n",
    "    for i, j in enumerate(bags):\n",
    "        errorTrain[i] = np.mean((Ytr - Ytr_rf[:,:i+1].mean(axis=1)>0.5))\n",
    "        errorValid[i] = np.mean((Yte - Yte_rf[:,:i+1].mean(axis=1)>0.5))\n",
    "        #print(\"{:02d} members: {} train, {} valid\".format(i+1,errorTrain,errorValid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(errorTrain)\n",
    "print(errorValid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class randomForest(ml.base.classifier):\n",
    "     def __init__(self, learners):\n",
    "         self.learners = learners\n",
    "         self.classes = learners[0].classes\n",
    "            \n",
    "     def predictSoft(self,X):\n",
    "         ysoft = np.zeros((X.shape[0], len(self.classes)))\n",
    "         for i in range(len(self.learners)): \n",
    "            ysoft[:,1] += self.learners[i].predict(X)\n",
    "         return ysoft / len(self.learners)\n",
    "    \n",
    "rf = randomForest(ensemble);\n",
    "print(\"AUC Train: \", rf.auc(Xtr,Ytr))\n",
    "print(\"AUC Valid: \", rf.auc(Xte,Yte))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ypred1 = rf.predictSoft(Xtest)\n",
    "Ypred2 = rf.predictSoft(Xte)\n",
    "\n",
    "Ypred1 = Ypred1[:,[1]]\n",
    "Ypred2 = Ypred2[:,[1]]\n",
    "\n",
    "np.savetxt('Pe1.txt', np.vstack( (np.arange(len(Ypred1)) , Ypred1[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',')\n",
    "np.savetxt('Pv1.txt', np.vstack( (np.arange(len(Ypred2)) , Ypred2[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "D = [0, 1, 2]\n",
    "\n",
    "ErrTrain = []\n",
    "ErrTest = []\n",
    "\n",
    "for i,d in enumerate(D):\n",
    "    XtrP = ml.transforms.fpoly(Xtr, d, bias=False) \n",
    "    XtrP,params = ml.transforms.rescale(XtrP)\n",
    "    lr = ml.linear.linearRegress( XtrP, Ytr )\n",
    "    \n",
    "    Phi = lambda X: ml.transforms.rescale(ml.transforms.fpoly(X, d, False), params)[0]\n",
    "    \n",
    "    ErrTrain.append(lr.mse(Phi(Xtr), Ytr))\n",
    "    ErrTest.append(lr.mse(Phi(Xte), Yte))\n",
    "    \n",
    "print(ErrTrain)\n",
    "print(ErrTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ypred1 = lr.predict(Phi(Xtest))\n",
    "Ypred2 = lr.predict(Phi(Xte))\n",
    "\n",
    "np.savetxt('Pe2.txt', np.vstack( (np.arange(len(Ypred1)) , Ypred1[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',')\n",
    "np.savetxt('Pv2.txt', np.vstack( (np.arange(len(Ypred2)) , Ypred2[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "XR,_  = ml.transforms.rescale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = ml.nnet.nnetRegress()\n",
    "\n",
    "nn.init_weights([14, 2, 1], 'random', XR, Y)\n",
    "\n",
    "nn.train(XR, Y, stopTol=-100, stepsize=0.1, stopIter=256)\n",
    "print(\"\\n\",nn.wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ypred1 = nn.predict(Xtest)\n",
    "Ypred2 = nn.predict(Xte)\n",
    "\n",
    "np.savetxt('Pe3.txt', np.vstack( (np.arange(len(Ypred1)) , Ypred1[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',')\n",
    "np.savetxt('Pv3.txt', np.vstack( (np.arange(len(Ypred2)) , Ypred2[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pv1 = np.genfromtxt('Pv0.csv',delimiter=',',skip_header=1)[:,1]\n",
    "Pv2 = np.genfromtxt('Pv1.csv',delimiter=',',skip_header=1)[:,1]\n",
    "Pv3 = np.genfromtxt('Pv2.csv',delimiter=',',skip_header=1)[:,1]\n",
    "\n",
    "Pe1 = np.genfromtxt('Pe0.csv',delimiter=',',skip_header=1)[:,1]\n",
    "Pe2 = np.genfromtxt('Pe1.csv',delimiter=',',skip_header=1)[:,1]\n",
    "Pe3 = np.genfromtxt('Pe2.csv',delimiter=',',skip_header=1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Sv = np.hstack((Pv1, Pv2, Pv3))\n",
    "stack = ml.linear.linearRegress(Sv,Yv, reg=1e-3)\n",
    "print \"** Stacked MSE: \",stack.mse(Sv,Yv)\n",
    "\n",
    "Se = np.hstack((Pe1,Pe2,Pe3))\n",
    "PeS = stack.predict(Se)\n",
    "np.savetxt('Stack.txt', np.vstack( (np.arange(len(PeS)) , PeS[:,0]) ).T, '%d, %.2f',header='ID,Prob1',comments='',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
